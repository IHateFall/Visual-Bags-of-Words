{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using Visual Bags of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_curve,auc\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read images and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image sets and data files are not uploaded due to large memory space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_st=75\n",
    "k=50\n",
    "knn=0\n",
    "dt=0\n",
    "svm=0\n",
    "rf=0\n",
    "\n",
    "infile=pd.read_csv('all_bow.csv')\n",
    "train_images= '../new_train_images'\n",
    "test_images='../new_test_images'\n",
    "\n",
    "train_img=[]\n",
    "for i in os.listdir(train_images):\n",
    "    if not i.startswith('.') and os.path.isfile(os.path.join(train_images, i)):\n",
    "            train_img.append(i)\n",
    "test_img=[]\n",
    "for i in os.listdir(test_images):\n",
    "    if not i.startswith('.') and os.path.isfile(os.path.join(test_images, i)):\n",
    "            test_img.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step one--Extract features and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = cv2.xfeatures2d.SIFT_create()\n",
    "def extract_words(path,im_set):\n",
    "    des_list = []\n",
    "    pred_list=[]\n",
    "    for pet in im_set:        \n",
    "        im=os.path.join(path,pet)\n",
    "        img=cv2.imread(im)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = extractor.detectAndCompute(img, None)\n",
    "        kmeans = KMeans(n_clusters=k,random_state=rand_st).fit(des)\n",
    "        prediction=kmeans.predict(des)\n",
    "        des_list.append(des)\n",
    "        pred_list.append(prediction)        \n",
    "    return des_list,pred_list\n",
    "step1=extract_words(train_images,train_img)    \n",
    "descriptors=step1[0]\n",
    "words=step1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step two--Vector quantization (new dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_table(word_list):\n",
    "    wordfreq=[]\n",
    "    for i in range(len(word_list)):\n",
    "        count = np.unique(word_list[i], return_counts=True)\n",
    "        wordfreq.append(count[1])\n",
    "    return wordfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step three--Validation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=count_table(words)\n",
    "train= pd.DataFrame(np.vstack(df))\n",
    "target_train=pd.read_csv('train_list.csv',header=None)\n",
    "train['target']=target_train.iloc[:,1]\n",
    "x_train=train.iloc[:,0:k]\n",
    "train.loc[train['target']=='cat','label']=0\n",
    "train.loc[train['target']=='dog','label']=1\n",
    "y_train=train['label']\n",
    "#sns.pairplot(x_train)\n",
    "#correlations=x_train.corr().round(2)\n",
    "dogs=train[train.target=='dog'].iloc[:,:k]\n",
    "cats=train[train.target=='cat'].iloc[:,:k]\n",
    "\n",
    "dog_count=dogs.sum(axis = 0, skipna = True) \n",
    "cat_count=cats.sum(axis = 0, skipna = True)\n",
    "\n",
    "#TEST SET\n",
    "step4=extract_words(test_images,test_img)\n",
    "test_words=step4[1]\n",
    "df2=count_table(test_words)\n",
    "test = pd.DataFrame(np.vstack(df2))\n",
    "target_test=pd.read_csv('test_list.csv',header=None)\n",
    "test['target']=target_test.iloc[:,1]\n",
    "x_test=test.iloc[:,0:k]\n",
    "test.loc[test['target']=='cat','label']=0\n",
    "test.loc[test['target']=='dog','label']=1\n",
    "y_test=test['label']  \n",
    "data=pd.concat([train,test])  \n",
    "x_data=data.iloc[:,0:k]\n",
    "y_data=data['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step four--Training classifiers and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if knn==1:\n",
    "    neigh = KNeighborsClassifier(n_neighbors=8)\n",
    "    neigh.fit(x_train, y_train) \n",
    "    pred=neigh.predict(x_test)\n",
    "    scores=neigh.score(x_test, y_test)  \n",
    "    print('KNN test accuracy',scores.round(3))\n",
    "    print(confusion_matrix(y_test, pred))  \n",
    "    print(classification_report(y_test, pred))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    print('KNN test AUC:',roc_auc.round(3))\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'} \n",
    "    scores = cross_validate(neigh,x_data,y_data,cv=5,scoring=scorers)                                                                                              \n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"KNN CV Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std()))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                             \n",
    "    print(\"KNN CV AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supported Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if svm==1:\n",
    "    svm=SVC(C=1, kernel='rbf', degree=3,random_state=rand_st)\n",
    "    svm.fit(x_train, y_train) \n",
    "    pred=svm.predict(x_test)\n",
    "    scores=svm.score(x_test, y_test)  \n",
    "    print('SVM test accuracy',scores.round(3))\n",
    "    print(confusion_matrix(y_test, pred))  \n",
    "    print(classification_report(y_test, pred))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    print('SVM AUC:',roc_auc)\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'} \n",
    "    scores = cross_validate(svm,x_data,y_data,cv=5,scoring=scorers)                                                                                              \n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"SVM CV Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std()))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                             \n",
    "    print(\"SVM CV AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std()))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rf==1:\n",
    "    rf=RandomForestClassifier(n_estimators=100, criterion='entropy',random_state=rand_st)\n",
    "    rf.fit(x_train, y_train) \n",
    "    pred=rf.predict(x_test)\n",
    "    scores=rf.score(x_test, y_test)  \n",
    "    print('Random Forest test accuracy',scores.round(3))\n",
    "    print(confusion_matrix(y_test, pred))  \n",
    "    print(classification_report(y_test, pred))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    print('Random Forest AUC:',roc_auc)\n",
    "    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'} \n",
    "    scores = cross_validate(rf,x_data,y_data,cv=5,scoring=scorers)                                                                                              \n",
    "    scores_Acc = scores['test_Accuracy']                                                                                                                                    \n",
    "    print(\"Random Forest CV Acc: %0.2f (+/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std()))                                                                                                    \n",
    "    scores_AUC= scores['test_roc_auc']                                                                             \n",
    "    print(\"Random Forest CV AUC: %0.2f (+/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "#svc_param_selection(x_train, y_train, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
