import os
import pandas as pd
import numpy as np
import cv2
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split,cross_validate
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix,roc_curve,auc
from matplotlib.legend_handler import HandlerLine2D
from sklearn.svm import SVC 
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
####PREPARING IMAGE SET AND GLOBAL VARIABLES####
rand_st=75
k=50
knn=0
dt=0
svm=0
rf=0

infile=pd.read_csv('all_bow.csv')
train_images= '../Chloe/new_train_images'
test_images='../Chloe/new_test_images'

train_img=[]
for i in os.listdir(train_images):
    if not i.startswith('.') and os.path.isfile(os.path.join(train_images, i)):
            train_img.append(i)
test_img=[]
for i in os.listdir(test_images):
    if not i.startswith('.') and os.path.isfile(os.path.join(test_images, i)):
            test_img.append(i)

####STEP 1----EXTRACT KEYPOINTS AND CLUSTERING####
extractor = cv2.xfeatures2d.SIFT_create()
def extract_words(path,im_set):
    des_list = []
    pred_list=[]
    for pet in im_set:        
        im=os.path.join(path,pet)
        img=cv2.imread(im)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        kp, des = extractor.detectAndCompute(img, None)
        kmeans = KMeans(n_clusters=k,random_state=rand_st).fit(des)
        prediction=kmeans.predict(des)
        des_list.append(des)
        pred_list.append(prediction)        
    return des_list,pred_list
step1=extract_words(train_images,train_img)    
descriptors=step1[0]
words=step1[1]


    
####STEP 2----CREATE COUNT TABLE OF EACH WORD####
def count_table(word_list):
    wordfreq=[]
    for i in range(len(word_list)):
        count = np.unique(word_list[i], return_counts=True)
        wordfreq.append(count[1])
    return wordfreq

####STEP 3----CONSTRUCT TRAIN/TEST SET####
df=count_table(words)
train= pd.DataFrame(np.vstack(df))
target_train=pd.read_csv('train_list.csv',header=None)
train['target']=target_train.iloc[:,1]
x_train=train.iloc[:,0:k]
train.loc[train['target']=='cat','label']=0
train.loc[train['target']=='dog','label']=1
y_train=train['label']
#sns.pairplot(x_train)
#correlations=x_train.corr().round(2)
dogs=train[train.target=='dog'].iloc[:,:k]
cats=train[train.target=='cat'].iloc[:,:k]

dog_count=dogs.sum(axis = 0, skipna = True) 
cat_count=cats.sum(axis = 0, skipna = True)

#TEST SET
step4=extract_words(test_images,test_img)
test_words=step4[1]
df2=count_table(test_words)
test = pd.DataFrame(np.vstack(df2))
target_test=pd.read_csv('test_list.csv',header=None)
test['target']=target_test.iloc[:,1]
x_test=test.iloc[:,0:k]
test.loc[test['target']=='cat','label']=0
test.loc[test['target']=='dog','label']=1
y_test=test['label']  
data=pd.concat([train,test])  
x_data=data.iloc[:,0:k]
y_data=data['label']

####STEP 4----TRAIN CLASSIFIERS AND RESULTS####
if knn==1:
    neigh = KNeighborsClassifier(n_neighbors=8)
    neigh.fit(x_train, y_train) 
    pred=neigh.predict(x_test)
    scores=neigh.score(x_test, y_test)  
    print('KNN test accuracy',scores.round(3))
    print(confusion_matrix(y_test, pred))  
    print(classification_report(y_test, pred))
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    print('KNN test AUC:',roc_auc.round(3))
    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'} 
    scores = cross_validate(neigh,x_data,y_data,cv=5,scoring=scorers)                                                                                              
    scores_Acc = scores['test_Accuracy']                                                                                                                                    
    print("KNN CV Acc: %0.2f (+/- %0.2f)" % (scores_Acc.mean(), scores_Acc.std()))                                                                                                    
    scores_AUC= scores['test_roc_auc']                                                                             
    print("KNN CV AUC: %0.2f (+/- %0.2f)" % (scores_AUC.mean(), scores_AUC.std()))                           

if dt==1:
    clf = DecisionTreeClassifier(criterion='entropy', splitter='best', random_state=rand_st)
    clf.fit(x_train, y_train)
    pred=clf.predict(x_test)
    scores=clf.score(x_test, y_test)  
    print('Decition Tree test accuracy',scores.round(3))
    print(confusion_matrix(y_test, pred))  
    print(classification_report(y_test, pred))
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    print('Decition Tree AUC:',roc_auc.round(3))
    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'} 
    scores = cross_validate(clf,x_data,y_data,cv=5,scoring=scorers)                                                                                              
    scores_Acc = scores['test_Accuracy']                                                                                                                                    
    print("Decision Tree CV Acc: %0.2f (+/- %0.2f)" % (scores_Acc.mean(), scores_Acc.std()))                                                                                                    
    scores_AUC= scores['test_roc_auc']                                                                             
    print("Decision Tree CV AUC: %0.2f (+/- %0.2f)" % (scores_AUC.mean(), scores_AUC.std()))   

if svm==1:
    svm=SVC(C=1, kernel='rbf', degree=3,random_state=rand_st)
    svm.fit(x_train, y_train) 
    pred=svm.predict(x_test)
    scores=svm.score(x_test, y_test)  
    print('SVM test accuracy',scores.round(3))
    print(confusion_matrix(y_test, pred))  
    print(classification_report(y_test, pred))
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    print('SVM AUC:',roc_auc)
    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'} 
    scores = cross_validate(svm,x_data,y_data,cv=5,scoring=scorers)                                                                                              
    scores_Acc = scores['test_Accuracy']                                                                                                                                    
    print("SVM CV Acc: %0.2f (+/- %0.2f)" % (scores_Acc.mean(), scores_Acc.std()))                                                                                                    
    scores_AUC= scores['test_roc_auc']                                                                             
    print("SVM CV AUC: %0.2f (+/- %0.2f)" % (scores_AUC.mean(), scores_AUC.std()))   
    
if rf==1:
    rf=RandomForestClassifier(n_estimators=100, criterion='entropy',random_state=rand_st)
    rf.fit(x_train, y_train) 
    pred=rf.predict(x_test)
    scores=rf.score(x_test, y_test)  
    print('Random Forest test accuracy',scores.round(3))
    print(confusion_matrix(y_test, pred))  
    print(classification_report(y_test, pred))
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    print('Random Forest AUC:',roc_auc)
    scorers = {'Accuracy': 'accuracy', 'roc_auc': 'roc_auc'} 
    scores = cross_validate(rf,x_data,y_data,cv=5,scoring=scorers)                                                                                              
    scores_Acc = scores['test_Accuracy']                                                                                                                                    
    print("Random Forest CV Acc: %0.2f (+/- %0.2f)" % (scores_Acc.mean(), scores_Acc.std()))                                                                                                    
    scores_AUC= scores['test_roc_auc']                                                                             
    print("Random Forest CV AUC: %0.2f (+/- %0.2f)" % (scores_AUC.mean(), scores_AUC.std()))   

####PARAMETERS TUNING####
def svc_param_selection(X, y, nfolds):
    Cs = [0.001, 0.01, 0.1, 1, 10]
    gammas = [0.001, 0.01, 0.1, 1]
    param_grid = {'C': Cs, 'gamma' : gammas}
    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)
    grid_search.fit(X, y)
    grid_search.best_params_
    return grid_search.best_params_
#svc_param_selection(x_train, y_train, 5)


def tune_dt():   
    max_depths = np.linspace(1, 32, 32, endpoint=True)
    train_results = []
    test_results = []
    for max_depth in max_depths:
       dt = DecisionTreeClassifier(max_depth=max_depth)
       dt.fit(x_train, y_train)
       train_pred = dt.predict(x_train)
       false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)
       roc_auc = auc(false_positive_rate, true_positive_rate)
       # Add auc score to previous train results
       train_results.append(roc_auc)
       y_pred = dt.predict(x_test)
       false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
       roc_auc = auc(false_positive_rate, true_positive_rate)
       # Add auc score to previous test results
       test_results.append(roc_auc)
    
    line1, = plt.plot(max_depths, train_results,'b', label='Train AUC')
    line2, = plt.plot(max_depths, test_results, 'r', label='Test AUC')
    plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
    plt.ylabel('AUC score')
    plt.xlabel('Tree depth')
    plt.show()

def tune_knn():
    neighbors = list(range(1,30))
    train_results = []
    test_results = []
    for n in neighbors:
       model = KNeighborsClassifier(n_neighbors=n)
       model.fit(x_train, y_train)
       train_pred = model.predict(x_train)
       false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)
       roc_auc = auc(false_positive_rate, true_positive_rate)
       train_results.append(roc_auc)
       y_pred = model.predict(x_test)
       false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
       roc_auc = auc(false_positive_rate, true_positive_rate)
       test_results.append(roc_auc)
    line1, = plt.plot(neighbors, train_results, 'b', label='Train AUC')
    line2, = plt.plot(neighbors, test_results, 'r', label='Test AUC')
    plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
    plt.ylabel('AUC score')
    plt.xlabel('n_neighbors')
    plt.show()

'''
count = np.unique(words[5], return_counts=True)
sns.countplot(words[5])
'''  
dataset_path = '../Chloe/new_train_images'

img_building = cv2.imread(os.path.join(dataset_path, '52.jpg'))
img_building = cv2.cvtColor(img_building, cv2.COLOR_BGR2RGB)  # Convert from cv's BRG default color order to RGB

orb = cv2.ORB_create()  # OpenCV 3 backward incompatibility: Do not create a detector with `cv2.ORB()`.
key_points, description = orb.detectAndCompute(img_building, None)
img_building_keypoints = cv2.drawKeypoints(img_building, 
                                           key_points, 
                                           img_building, 
                                           flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) # Draw circles.
plt.figure(figsize=(16, 16))
plt.title('SIFT Interest Points')
plt.imshow(img_building_keypoints); plt.show()

##MATCHING FEATURES##
def image_detect_and_compute(detector, img_name):
    """Detect and compute interest points and their descriptors."""
    img = cv2.imread(os.path.join(dataset_path, img_name))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    kp, des = detector.detectAndCompute(img, None)
    return img, kp, des
    

def draw_image_matches(detector, img1_name, img2_name, nmatches=10):
    """Draw ORB feature matches of the given two images."""
    img1, kp1, des1 = image_detect_and_compute(detector, img1_name)
    img2, kp2, des2 = image_detect_and_compute(detector, img2_name)
    
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(des1, des2)
    matches = sorted(matches, key = lambda x: x.distance) # Sort matches by distance.  Best come first.
    
    img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:nmatches], img2, flags=2) # Show top 10 matches
    plt.figure(figsize=(16, 16))
    plt.title(type(detector))
    plt.imshow(img_matches); plt.show()
    

orb = cv2.ORB_create()
draw_image_matches(orb, '67.jpg', '24.jpg')
